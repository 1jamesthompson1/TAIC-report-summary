{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What\n",
    "\n",
    "As discussed in https://github.com/1jamesthompson1/TAIC-report-summary/issues/130 there is a requirement for recommendations to be extracted and linked. Due to the discovering of a dataset the extraction is no longer needed and focus on linking can be made.\n",
    "\n",
    "## How to do it\n",
    "\n",
    "I have two datasets to work with.\n",
    "\n",
    "Firstly is the recommendation dataset from TAIC this dataset can be considered trustworthy and complete.\n",
    "Secondly I have the safety issue extracted from the reports. This has a problem that as it is from the engine it cannot be fully trusted. What I will do instead will start with just the ones extracted using regexes so that I know they are true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All of the modules needed\n",
    "\n",
    "To keep things as transparent as possible I will add all of the dependencies at the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the engine\n",
    "import engine.Extract_Analyze.ReportExtracting as ReportExtracting\n",
    "from engine.OpenAICaller import openAICaller\n",
    "\n",
    "\n",
    "# Third party\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import yaml\n",
    "\n",
    "# Built in\n",
    "import os\n",
    "import re\n",
    "import importlib\n",
    "import textwrap\n",
    "\n",
    "pd.options.mode.copy_on_write = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting datasets\n",
    "\n",
    "My goal here is to have a single dataset that has 3 columns.\n",
    "\n",
    "These are report_id, safety_issue and recommendation. *Note that there will be more columns but this is the idea of the three things conveyed by each row*\n",
    "\n",
    "This means that there will be a row for all of the safety issues in each report and for each safety issue row there will also be a row for each recommendation from the report. Therefore I will be making a very long dataset\n",
    "\n",
    "In the next section I will work on adding the fourth column of whether they are linked and from their I can easily filter out the nonexistant connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are a few reports that have problems for various reasons that are just not worth the effort to include. These will be excluded from this work\n",
    "\n",
    "reports_to_exclude = [\n",
    "    '2022_203', # stevedore joint investigation that doesn't follow usual format\n",
    "    '2022_202', # \"\"\n",
    "    '2023_010', # This is not a report and instead just a protection order\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TAIC dataset\n",
    "\n",
    "This data set just comes from a xlsx files but needs to be cleaned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_TAIC_recommendations_df = pd.read_excel('TAIC_recommendations_04_04_2024.xlsx')\n",
    "\n",
    "cleaned_TAIC_recommendations_df = original_TAIC_recommendations_df.copy()\n",
    "\n",
    "cleaned_TAIC_recommendations_df['recommendation_id'] = cleaned_TAIC_recommendations_df['Number']\n",
    "\n",
    "cleaned_TAIC_recommendations_df['recommendation_text'] = cleaned_TAIC_recommendations_df['Recommendation']\n",
    "\n",
    "cleaned_TAIC_recommendations_df.dropna(subset=['recommendation_text', 'Inquiry'], inplace = True)\n",
    "\n",
    "rows_deleted = len(original_TAIC_recommendations_df) - len(cleaned_TAIC_recommendations_df)\n",
    "print(f\"Deleting {rows_deleted} rows with NAs in either recommendation_text or Inquiry\")\n",
    "\n",
    "\n",
    "# find all rows that dont match regex on column 'Inquiry'\n",
    "inquiry_regex = r'^(((AO)|(MO)|(RO))-[12][09][987012]\\d-[012]\\d{2})$'\n",
    "cleaned_TAIC_recommendations_df = cleaned_TAIC_recommendations_df[cleaned_TAIC_recommendations_df['Inquiry'].str.match(inquiry_regex)]\n",
    "\n",
    "# printout how many rows were dropped\n",
    "print(f\"Dropped {len(original_TAIC_recommendations_df) - len(cleaned_TAIC_recommendations_df) - rows_deleted} rows that didn't match regex\")\n",
    "\n",
    "# Show the rows that were dropped\n",
    "# display(original_TAIC_recommendations_df[~original_TAIC_recommendations_df.index.isin(cleaned_TAIC_recommendations_df.index)])\n",
    "\n",
    "cleaned_TAIC_recommendations_df['report_id'] = cleaned_TAIC_recommendations_df['Inquiry'].apply(lambda x: \"_\".join(x.split('-')[1:3]))\n",
    "\n",
    "# Some of the recommendations have more than just hte recommendation itself. I will use regex to rid of these and can store the extra context in another column\n",
    "cleaned_TAIC_recommendations_df['has_extra_context'] = cleaned_TAIC_recommendations_df['recommendation_text'].apply(lambda x: re.search(r'[\\s\\S]{35,}the commission recommend[\\s\\S]{100,}', x, re.IGNORECASE) is not None)\n",
    "cleaned_TAIC_recommendations_df['extra_recommendation_context'] = cleaned_TAIC_recommendations_df.apply(lambda x: re.search(r'([\\s\\S]*)the commission recommend', x['recommendation_text'], re.IGNORECASE).group(1) if x['has_extra_context'] else None, axis=1)\n",
    "cleaned_TAIC_recommendations_df['recommendation'] = cleaned_TAIC_recommendations_df.apply(lambda x: x['recommendation_text'].replace(x['extra_recommendation_context'], '') if x['has_extra_context'] else x['recommendation_text'], axis=1)\n",
    "\n",
    "\n",
    "# To make it simpler later on all other columns are being removed.\n",
    "\n",
    "cleaned_TAIC_recommendations_df = cleaned_TAIC_recommendations_df[['report_id', 'recommendation_id', 'recommendation']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Safety extraction dataset\n",
    "\n",
    "I will need to extract all of the direct safety issues from the reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reports_path = 'output'\n",
    "\n",
    "reports = [name for name in os.listdir(reports_path) if os.path.isdir(os.path.join(reports_path, name))]\n",
    "\n",
    "reports = [report for report in reports if report not in reports_to_exclude]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old method\n",
    "\n",
    "It was previously done by reading them with regex.\n",
    "However now I have a dataset that was run with the LLM. This is completely reliable but it is larger and better than before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Clean the outputs folder\n",
    "\n",
    "# for report in reports:\n",
    "#     files = os.listdir(os.path.join(reports_path, report))\n",
    "\n",
    "#     for file in files:\n",
    "#         if not re.match(fr\"{report}((.pdf)|(.txt))\", file):\n",
    "#             print(os.path.join(reports_path, report, file))\n",
    "#             os.remove(os.path.join(reports_path, report, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function copied from 'safety_issue_extraction.ipynb'\n",
    "def  read_or_create_important_text_file(path, report_id, text):\n",
    "    important_text_path = os.path.join(path, report_id, f'{report_id}_important_text.txt')\n",
    "\n",
    "    if not os.path.isfile(important_text_path):\n",
    "        important_text, pages = ReportExtracting.ReportExtractor(text, report_id).extract_important_text()\n",
    "\n",
    "        important_text = \"\" if important_text == None else important_text\n",
    "\n",
    "        with open(important_text_path, 'w') as stream:\n",
    "            stream.write(important_text)\n",
    "\n",
    "        return important_text\n",
    "    \n",
    "    with open(important_text_path, 'r') as stream:\n",
    "        important_text = stream.read()\n",
    "        \n",
    "    important_text = None if important_text == \"\" else important_text\n",
    "\n",
    "    return important_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get safety issues extracted from all reports\n",
    "importlib.reload(ReportExtracting)\n",
    "\n",
    "safety_issues = []\n",
    "\n",
    "for report in reports:\n",
    "    \n",
    "    with open(os.path.join(reports_path, report, f'{report}.txt'), 'r') as stream:\n",
    "        text = stream.read()\n",
    "\n",
    "    important_text = read_or_create_important_text_file(reports_path, report, text)\n",
    "\n",
    "    if important_text == None:\n",
    "        print(\" No safety issues from \" + report + \" as important text could not be found\")\n",
    "        continue\n",
    "\n",
    "    extracted_safety_issues = ReportExtracting.SafetyIssueExtractor(text, report)._extract_safety_issues_with_regex(important_text)\n",
    "\n",
    "    safety_issues.append({\n",
    "        'report_id': report,\n",
    "        'safety_issues': extracted_safety_issues\n",
    "    })\n",
    "\n",
    "safety_issues_df = pd.DataFrame(safety_issues)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lengthen it so that each safety issue has its own row\n",
    "safety_issues_df = safety_issues_df.explode('safety_issues')\n",
    "\n",
    "# Remove reports without explicit safety issues\n",
    "safety_issues_df.dropna(subset=['safety_issues'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the safety issues that have non standard characters\n",
    "\n",
    "standard_characters_regex = r'''^[\\w,.\\s()'\"/\\-%]+$'''\n",
    "\n",
    "non_standard_safety_issues = safety_issues_df[~safety_issues_df['safety_issues'].str.match(standard_characters_regex)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "safety_issues_df = safety_issues_df[safety_issues_df['safety_issues'].str.match(standard_characters_regex)]\n",
    "print(f\"  Removed {len(non_standard_safety_issues)} non standard safety issues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New method with LLM\n",
    "\n",
    "As I have the update data set from https://github.com/1jamesthompson1/TAIC-report-summary/pull/141\n",
    "\n",
    "Therefore I can simple read that datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "safety_issues = []\n",
    "\n",
    "for report in reports:\n",
    "    \n",
    "    SI_file_path = os.path.join(reports_path, report, f\"{report}_safety_issues.yaml\")\n",
    "\n",
    "    if os.path.exists(SI_file_path):\n",
    "        with open(SI_file_path, \"r\") as f:\n",
    "            safety_issues.append({\n",
    "                \"report_id\": report,\n",
    "                \"safety_issue\": yaml.safe_load(f)\n",
    "                })\n",
    "    else:\n",
    "        print(f\"Could not find safety issues for {SI_file_path}\")\n",
    "\n",
    "safety_issues_df = pd.DataFrame(safety_issues)\n",
    "safety_issues_df = safety_issues_df.explode(\"safety_issue\")\n",
    "\n",
    "safety_issues_df['safety_issue'] = safety_issues_df['safety_issue'].apply(lambda x: x['safety_issue'])\n",
    "\n",
    "display(safety_issues_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the two datasets\n",
    "\n",
    "Now that I have the two data sets `safety_issues_df` and `cleaned_TAIC_recommendations_df` I can combine them together to be compared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the safety issues and the recommendations for each report\n",
    "\n",
    "combined_df = []\n",
    "\n",
    "for report in safety_issues_df['report_id'].unique():\n",
    "\n",
    "    report_safety_issues = safety_issues_df[safety_issues_df['report_id'] == report]['safety_issue']\n",
    "\n",
    "    report_recommendations = cleaned_TAIC_recommendations_df[cleaned_TAIC_recommendations_df['report_id'] == report]['recommendation']\n",
    "\n",
    "    for safety_issue in report_safety_issues:\n",
    "        for recommendation in report_recommendations:\n",
    "            combined_df.append({\n",
    "                'report_id': report,\n",
    "                'safety_issue': safety_issue,\n",
    "                'recommendation': recommendation\n",
    "            })\n",
    "\n",
    "combined_df = pd.DataFrame(combined_df)\n",
    "\n",
    "print(f\"  There are {len(combined_df)} safety issues and recommendations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing link analysis\n",
    "\n",
    "Now that I have a big dataset I need to compare all the possible connections and see which ones stick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many tokens am I dealing with\n",
    "\n",
    "As I have a large data set with 500~ rows I need to know roughly how many tokens. Because this will give me a rough cost guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count up the tokens in the safety issues and recommendations\n",
    "\n",
    "def how_many_tokens(df):\n",
    "\n",
    "    df['safety_issue_tokens'] = df['safety_issue'].apply(lambda x: sum(openAICaller.get_tokens(x)))\n",
    "    df['recommendation_tokens'] = df['recommendation'].apply(lambda x: sum(openAICaller.get_tokens(x)))\n",
    "\n",
    "    total_number_of_tokens = sum(df['safety_issue_tokens']) + sum(df['recommendation_tokens'])\n",
    "\n",
    "    return total_number_of_tokens\n",
    "\n",
    "def rough_cost(df):\n",
    "\n",
    "    tokens = how_many_tokens(df)\n",
    "\n",
    "    return round(tokens/1000 * 0.01, 2)\n",
    "\n",
    "print(f\"I am dealing with {len(combined_df)} possible combinations. The cost to read with gpt 4 turbo is ${rough_cost(combined_df)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying out linking with sample\n",
    "\n",
    "I am going to simply look at 10 random reports and see how to do some comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the play dataset\n",
    "\n",
    "playset_reports = combined_df['report_id'].sample(10, random_state=42)\n",
    "\n",
    "combined_df_playset = combined_df[combined_df['report_id'].isin(playset_reports)]\n",
    "\n",
    "print(f\"  There are {len(combined_df_playset)} safety issues and recommendations in the playset.\\nIt will cost roughly ${rough_cost(combined_df_playset)} to run through.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_SI_recommendation_link(SI, recommendation):\n",
    "    response =openAICaller.query(\n",
    "        system = f\"\"\"\n",
    "You are going to help me find find links between recommendations and safety issues identified in transport accident investigation reports.\n",
    "\n",
    "Each transport accident investigation report will identify safety issues. These reports will then issue recommendation that will address one or more of the safety issues identfied in the report.\n",
    "\n",
    "For each pair given you need to respond with one of three answers.\n",
    "\n",
    "- None (The recommendation is not directly related to the safety issue)\n",
    "- Possible (The recommendation is reasonably likely to directly address the safety issue)\n",
    "- Confirmed (The recommendation explicitly mention that safety issue that it is trying address)\n",
    "\"\"\",\n",
    "        user = f\"\"\"\n",
    "Here is the recommendation:\n",
    "\n",
    "{recommendation}\n",
    "\n",
    "Here is the safety issue:\n",
    "\n",
    "{SI}\n",
    "\\\n",
    "\"\"\",\n",
    "        model = \"gpt-4\",\n",
    "        temp = 0)\n",
    "    \n",
    "    if response in ['None', 'Possible', 'Confirmed']:\n",
    "        return response\n",
    "    else:\n",
    "        print(f\"Model response is incorrect and is {response}\")\n",
    "        return 'undetermined'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for pkl file and if not found remake it\n",
    "redo = False\n",
    "if os.path.exists('links.pkl'):\n",
    "\n",
    "    print(\" Found pkl file\")\n",
    "    found_df = pd.read_pickle('links.pkl')\n",
    "\n",
    "    if found_df.drop(columns='link').equals(combined_df_playset.drop(columns='link', errors='ignore')):\n",
    "        print(\"  Pkl file is up to date\")\n",
    "        combined_df_playset = found_df\n",
    "    else:\n",
    "        redo =True\n",
    "else:\n",
    "    redo = True\n",
    "\n",
    "if redo:\n",
    "    print(\"Remaking the file\")\n",
    "    combined_df_playset['link'] = combined_df_playset.apply(lambda x: evaluate_SI_recommendation_link(x['safety_issue'], x['recommendation']), axis=1)\n",
    "    combined_df_playset.to_pickle('links.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the linking results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df_playset['link'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_link_visualization(df, report_id):\n",
    "    '''\n",
    "    Create a picture that shows both the recommendations and the safety issues fro a report. There will be arrows showing the link between the two.\n",
    "    '''\n",
    "    # Create a directed graph\n",
    "    print(\"Creating visualization\")\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    NODE_WIDTH = 50\n",
    "\n",
    "    # Preemptively wrap the text\n",
    "    df['recommendation'] = df['recommendation'].apply(lambda x: \"\\n\".join(textwrap.wrap(x, width=NODE_WIDTH)))\n",
    "    df['safety_issue'] = df['safety_issue'].apply(lambda x: \"\\n\".join(textwrap.wrap(x, width=NODE_WIDTH)))\n",
    "\n",
    "    # Add nodes for the 'extracted' and 'inferred' indices\n",
    "    for i, text in enumerate(df['recommendation'].unique()):\n",
    "        G.add_node(text, pos=(0, i))\n",
    "\n",
    "    for i, issue in enumerate(df['safety_issue'].unique()):\n",
    "        G.add_node(issue, pos=(3, i))\n",
    "\n",
    "\n",
    "    # Add edges between the matched indices\n",
    "    for _, row in df.iterrows():\n",
    "        # Add solid arrow\n",
    "        if row['link'] == 'Confirmed':\n",
    "            G.add_edge(row['recommendation'], row['safety_issue'], color='red', style='solid', alpha =1)\n",
    "\n",
    "        # Add dotted arrow\n",
    "        elif row['link'] == 'Possible':\n",
    "            G.add_edge(row['recommendation'], row['safety_issue'], color='blue', style='dashed', alpha = 0.5)\n",
    "\n",
    "\n",
    "    max_num_of_nodes_column = max(\n",
    "        len(df['recommendation'].unique()),\n",
    "        len(df['safety_issue'].unique())\n",
    "        )\n",
    "\n",
    "    # Draw the graph\n",
    "    pos = nx.get_node_attributes(G, 'pos')\n",
    "\n",
    "    plt.figure(figsize=(10, max_num_of_nodes_column * 5))  \n",
    "    nx.draw_networkx_nodes(G, pos, node_color='lightblue', node_size=[len(node) * NODE_WIDTH for node in G.nodes()])\n",
    "    nx.draw_networkx_labels(G, pos, font_size=7)\n",
    "    nx.draw_networkx_edges(G, pos, arrows=True, edge_color=nx.get_edge_attributes(G, 'color').values(), style=list(nx.get_edge_attributes(G, 'style').values()), alpha = list(nx.get_edge_attributes(G, 'alpha').values()))\n",
    "\n",
    "    plt.xlim(-1, 4.5)  # Add buffer to the outside side edges\n",
    "    plt.ylim(-1, max_num_of_nodes_column*1)  # Add buffer to the outside top and bottom edges\n",
    "\n",
    "    # Add report ID and headers\n",
    "    plt.title(f'Report ID: {report_id}')\n",
    "    plt.text(0, max_num_of_nodes_column-0.2, 'Recommendations', fontsize=12, ha='center')\n",
    "    plt.text(3, max_num_of_nodes_column-0.2, 'Safety issue', fontsize=12, ha='center')\n",
    "    plt.text(1.5, max_num_of_nodes_column-0.5, 'Arrow indicates that the recommendation is indicated to solve the safety issue by the LLM', fontsize=6, ha='center')\n",
    "\n",
    "    if not os.path.exists('visualization_of_links'):\n",
    "        os.mkdir('visualization_of_links')\n",
    "\n",
    "    plt.savefig(os.path.join('visualization_of_links', f'{report_id}_comparison_visualization.png'))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make lots of d which just have one sort of report_id. THen send each individual one to the make visualization function\n",
    "\n",
    "for report_id in combined_df_playset['report_id'].unique():\n",
    "    d = combined_df_playset[combined_df_playset['report_id'] == report_id]\n",
    "\n",
    "    make_link_visualization(d, report_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the linking for just 2019_006\n",
    "\n",
    "df_2019_006 = combined_df[combined_df['report_id'] == '2019_006']\n",
    "\n",
    "df_2019_006['link'] = df_2019_006.apply(lambda row: evaluate_SI_recommendation_link(row['safety_issue'], row['recommendation']), axis = 1)\n",
    "\n",
    "make_link_visualization(df_2019_006, '2019_006')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am comparing this too what was done by Ingrid. It has got all of the correct links with only adding an extra link. This is good as clearly gpt 4 does a much better job than gpt 3.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing out analysis\n",
    "\n",
    "\n",
    "The two identified problems are \n",
    "- Too many links we only need one link type\n",
    "- There are recommendations without any links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations with links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find recommendations from combined_df_playset that dont have a linked safety issue\n",
    "\n",
    "def find_unlinked_recommendations(df):\n",
    "    all_recommendations = df[['report_id', 'recommendation']].drop_duplicates()\n",
    "\n",
    "    linked_recommendations = df[df['link'] == \"Confirmed\"]\n",
    "\n",
    "    unlinked_recommendations = all_recommendations[~all_recommendations['recommendation'].isin(linked_recommendations['recommendation'])]\n",
    "\n",
    "    return unlinked_recommendations\n",
    "\n",
    "find_unlinked_recommendations(combined_df_playset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I will look through the 5 reports that have unlinked recommendations.\n",
    "\n",
    "2010_009\n",
    "This report has really short safety issues. This can make it hard for it to find anything to link to.\n",
    "\n",
    "2016_206\n",
    "One is missing a red link but does have a blue link. \n",
    "This link could be upgrades to red if needed.\n",
    "\n",
    "2013_005\n",
    "Vague wordings that don't make it clear that they are addressing each other.\n",
    "The recommendation is specific where both of the safety issues are more general.\n",
    "\n",
    "2014_005\n",
    "The first missing recommendation about seat belts does not seem to have an associated safety issue.\n",
    "Recommendations regarding the vortex effect has a blue link that seems reasonable.\n",
    "\n",
    "2011_204\n",
    "There are not many direct links here but the two blue links will work.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taic-report-engine-vkGeZcZ8-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
