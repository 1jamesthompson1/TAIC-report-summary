{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What\n",
    "\n",
    "This is going to add the content extraction of the reports form atsb and tsbi nto the engine.\n",
    "\n",
    "It carries on the work from #257 of adding pdf text extraction to the engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from plotnine import ggplot, geom_histogram, aes, facet_wrap\n",
    "\n",
    "import engine.extract.ReportExtracting as ReportExtracting\n",
    "\n",
    "import importlib\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "importlib.reload(ReportExtracting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I will setup some of the global values needed for this workbook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = '../../output'\n",
    "report_text = pd.read_pickle(os.path.join(output_folder, 'parsed_reports.pkl'))\n",
    "report_text['year'] = report_text['report_id'].str.extract('(\\d{4})').astype(int)\n",
    "report_text['mode'] = report_text['report_id'].str.extract('_([amr])_')\n",
    "report_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ATSB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ReportExtracting)\n",
    "atsb_reports = report_text[report_text['report_id'].str.contains('ATSB')]\n",
    "atsb_reports['content_section'] = atsb_reports.apply(\n",
    "    lambda x: ReportExtracting.ReportExtractor(x['text'], x['report_id']).extract_contents_section(), axis=1\n",
    ")\n",
    "atsb_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(atsb_reports['content_section'].notna().value_counts())\n",
    "\n",
    "failed = atsb_reports[atsb_reports['content_section'].isnull()]\n",
    "\n",
    "(\n",
    "    ggplot(atsb_reports.assign(\n",
    "        has_content_section=atsb_reports['content_section'].notna(),\n",
    "    ), aes(x='year'))\n",
    "    + geom_histogram()\n",
    "    + facet_wrap(['mode', 'has_content_section',], ncol=2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ATSB has two sorts of reports. Full investigation and short ones. For the short ones I will not extract the content section. The content section is only used to find the important text to instead I will just provide the wohle text if it is not too long. Most f the short rpeorts are only about 2-5k token which is really not much.\n",
    "\n",
    "For ATSB full we have 1000 that have been extracted alright."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atsb_reports['content_section_len'] = atsb_reports['content_section'].map(lambda x: len(x) if x is not None else 0)\n",
    "atsb_reports.sort_values('content_section_len', ascending=False, inplace=True)\n",
    "\n",
    "atsb_reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking at this is seems that the content section extraction is accurate. I will add some tests in. Furthermore I will look at what is missed out and see if it is reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed['text_len'] = failed['text'].map(len)\n",
    "failed.sort_values('text_len', ascending=False, inplace=True)\n",
    "failed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems to me that it is reasonable to ignore the failed reports. Most of them are small so the whole report can just be used. For the 50 or so large failed rpeort it can be left for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TSB is currently running into the issue that it doesn't have content sections for mosts of its reports. I will do ATSB first and will hopefully have a more robust content section extractor. Otherwise I will look into having itgenerate a content sections based on regex searches of the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsb_reports = report_text[report_text['report_id'].str.startswith('TSB')]\n",
    "\n",
    "importlib.reload(ReportExtracting)\n",
    "tsb_reports['content_section'] = tsb_reports.apply(\n",
    "    lambda x: ReportExtracting.ReportExtractor(x['text'], x['report_id']).extract_contents_section(), axis=1\n",
    ")\n",
    "tsb_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tsb_reports['content_section'].notna().value_counts())\n",
    "# Make histogram of years with two colours for content section exist and not\n",
    "failed = tsb_reports[tsb_reports['content_section'].isnull()]\n",
    "(\n",
    "    ggplot(tsb_reports.assign(has_content_section=tsb_reports['content_section'].notna()), aes(x='year'))\n",
    "    + geom_histogram()\n",
    "    + facet_wrap('has_content_section', ncol=1)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TAIC\n",
    "\n",
    "Even though it is already supported I should know the full information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taic_reports = report_text[report_text['report_id'].str.startswith('TAIC')]\n",
    "\n",
    "importlib.reload(ReportExtracting)\n",
    "taic_reports['content_section'] = taic_reports.apply(\n",
    "    lambda x: ReportExtracting.ReportExtractor(x['text'], x['report_id']).extract_contents_section(), axis=1\n",
    ")\n",
    "taic_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(taic_reports['content_section'].notna().value_counts())\n",
    "\n",
    "failed = taic_reports[taic_reports['content_section'].isnull()]\n",
    "\n",
    "(\n",
    "    ggplot(taic_reports.assign(has_content_section=taic_reports['content_section'].notna()), aes(x='year'))\n",
    "    + geom_histogram()\n",
    "    + facet_wrap('has_content_section', ncol=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 87 failed and 432 true before i start making changing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first test there is about 10% failed for TAIC, 50% for ATSB and 16% for TSB.\n",
    "That is just using the regular expression as it currently is.\n",
    "\n",
    "We can see that TAIC is only failing once it gets back before 2005 so that can be ignored for now. However both TSB and ATSB have a lot of missing content sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to text files parsed files to let me inspect them\n",
    "shutil.rmtree('parsed_reports/', ignore_errors=True)\n",
    "\n",
    "os.makedirs('parsed_reports/', exist_ok=True)\n",
    "for index, text, content_section in failed[['report_id', 'text', 'content_section']].sample(10, random_state=42).to_records(index=False):\n",
    "    with open(os.path.join('parsed_reports', f'{index}.txt'), 'w') as f:\n",
    "        f.write(text)\n",
    "    with open(os.path.join('parsed_reports', f'{index}_content_section.txt'), 'w') as f:\n",
    "        f.write(content_section if content_section is not None else '')\n",
    "    shutil.copy(os.path.join(output_folder, 'report_pdfs', f\"{index}.pdf\"), os.path.join('parsed_reports', f\"{index}.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_id = \"ATSB_r_2021_002\"\n",
    "text = report_text.query(f'report_id == \"{report_id}\"').text.values[0]\n",
    "with open(\"individual.txt\", \"w\") as f:\n",
    "    f.write(text)\n",
    "importlib.reload(ReportExtracting)\n",
    "parsed_text = ReportExtracting.ReportExtractor(text, report_id).extract_contents_section()\n",
    "\n",
    "with open(\"individual-content-section.txt\", 'w') as f:\n",
    "    f.write(parsed_text if parsed_text is not None else '')\n",
    "\n",
    "\n",
    "for pdf in [pdf for pdf in os.listdir() if pdf.endswith('.pdf')]:\n",
    "    os.remove(pdf)\n",
    "shutil.copy(os.path.join(output_folder, 'report_pdfs', f\"{report_id}.pdf\"), f\"{report_id}.pdf\")\n",
    "\n",
    "\n",
    "display(parsed_text[:15])\n",
    "display(parsed_text[-15:])\n",
    "print(len(parsed_text))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
