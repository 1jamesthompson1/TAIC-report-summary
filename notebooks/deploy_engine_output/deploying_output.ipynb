{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What\n",
    "\n",
    "As part of the produciton challenge #172. I need to be able to upload the results to an external server.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local\n",
    "\n",
    "# Third Party\n",
    "import lancedb\n",
    "import pandas as pd\n",
    "\n",
    "# Built in\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload output to viewer vector_db\n",
    "The end goal will be to take the embeddings datasets and put them into a vector database that is in the cloud.\n",
    "\n",
    "However right not I am not working on it so I can just create this local script that will take the embedding folder and move it into a vector_db database within the viewer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = lancedb.connect(\"../../viewer/vector_db\")\n",
    "db.table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_text_embeddings = pd.read_pickle(\"../../output/embeddings/important_text_embeddings.pkl\")\n",
    "\n",
    "important_text_embeddings.rename(columns={'important_text_embedding': 'vector'}, inplace=True)\n",
    "db.create_table(\"important_text_embeddings\", important_text_embeddings, mode=\"overwrite\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations_embeddings = pd.read_pickle(\"../../output/embeddings/recommendations_embeddings.pkl\")\n",
    "\n",
    "recommendations_embeddings.rename(columns={'recommendation_embedding': 'vector'}, inplace=True)\n",
    "db.create_table(\"recommendation_embeddings\", recommendations_embeddings, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_sections_embeddings = pd.read_pickle(\"../../output/embeddings/report_sections_embeddings.pkl\")\n",
    "\n",
    "report_sections_embeddings.rename(columns={'section_embedding': 'vector'}, inplace=True)\n",
    "section_table = db.create_table(\"report_section_embeddings\", report_sections_embeddings, mode=\"overwrite\")\n",
    "\n",
    "section_table.create_fts_index(\"section_text\", replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "safety_issues_embeddings = pd.read_pickle(\"../../output/embeddings/safety_issues_embeddings.pkl\")\n",
    "\n",
    "safety_issues_embeddings.rename(columns={'safety_issue_embedding': 'vector'}, inplace=True)\n",
    "si_table = db.create_table(\"safety_issue_embeddings\", safety_issues_embeddings, mode=\"overwrite\")\n",
    "\n",
    "si_table.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get recomemdnations linked to safety issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_si_links = pd.read_pickle(\"../../output/recommendation_safety_issue_links.pkl\")\n",
    "rec_si_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_si_links_long = pd.concat(\n",
    "    rec_si_links['recommendation_links'].tolist(),\n",
    "    ignore_index=True\n",
    ")\n",
    "rec_si_links_long = rec_si_links_long.query('link == \"Confirmed\"')\n",
    "rec_si_links_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Squish it so that it ijust a list of safety issue ids with the recommendations\n",
    "\n",
    "grouped_df = rec_si_links_long.groupby('safety_issue_id').apply(\n",
    "    lambda x: x[['recommendation_id', 'recommendation', 'recipient']].reset_index(drop=True)\n",
    ").reset_index().drop('level_1', axis=1)\n",
    "\n",
    "grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "safety_issue_recommendations_table = db.create_table(\n",
    "    'safety_issue_recommendations',\n",
    "    grouped_df,\n",
    "    mode = \"overwrite\"\n",
    ")\n",
    "\n",
    "safety_issue_recommendations_table.search().where(\"safety_issue_id = '2000_004_2'\").to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating test vector_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = '../../tests/data/vector_db'\n",
    "\n",
    "test_db = lancedb.connect(uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "si_table = test_db.create_table(\n",
    "    'safety_issue_embeddings',\n",
    "    safety_issues_embeddings.sample(frac=0.1, random_state = 42),\n",
    "    mode = \"overwrite\"\n",
    ")\n",
    "\n",
    "si_table.create_fts_index('safety_issue', replace=True)\n",
    "\n",
    "si_table.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections_table = test_db.create_table(\n",
    "    'report_section_embeddings',\n",
    "    section_text_embeddings.sample(frac=0.1, random_state = 42),\n",
    "    mode = \"overwrite\"  \n",
    ")\n",
    "sections_table.create_fts_index('section_text', replace=True)\n",
    "\n",
    "sections_table.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "safety_issue_recommendations_test_table = test_db.create_table(\n",
    "    'safety_issue_recommendations',\n",
    "    grouped_df.sample(frac=0.1, random_state = 42),\n",
    "    mode = \"overwrite\"\n",
    ")\n",
    "\n",
    "safety_issue_recommendations_test_table.to_pandas().query('safety_issue_id == \"2002_007_1\"')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
