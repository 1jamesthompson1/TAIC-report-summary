{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What \n",
    "\n",
    "This is related to #269.\n",
    "\n",
    "To do recommendation exrtaction I need to complete a few tasks:\n",
    "\n",
    "- [ ] Web scraping of TSB for its recommendations\n",
    "- [ ] Safety action section extraction for ATSB and TSB (depending on if TSB recommendation dataset is in fact complete)\n",
    "- [ ] Safety action section parsing to gedt the recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import engine.gather.WebsiteScraping as WebsiteScraping\n",
    "import engine.extract.ReportExtracting as ReportExtracting\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "importlib.reload(WebsiteScraping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scraping of TSB\n",
    "\n",
    "Firstly I need to scrape the recommendations of the TSB website.\n",
    "\n",
    "This will be done in the `WebsiteScraping` module.\n",
    "\n",
    "I am not sure if this recommendations dataset is complete or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(WebsiteScraping)\n",
    "\n",
    "recommendation_scraper = WebsiteScraping.TSBRecommendationsScraper('tsb_recommendations', refresh=False)\n",
    "\n",
    "recommendation_scraper.extract_recommendations_from_website()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsb_recommendations = pd.read_pickle('tsb_recommendations')\n",
    "tsb_recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the current recommendations looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taic_recommendations =  pd.read_pickle('../../output/recommendations.pkl')\n",
    "\n",
    "example_taic_recommendation = taic_recommendations.loc[213, 'recommendations']\n",
    "example_taic_recommendation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking through the recommendations. I think that they are a compelte amount. Even if there are some larger gaps.\n",
    "\n",
    "I have spot checked the rail and the gaps there seem to check out as the none of the reports in that few years had any recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Safety Action section extraction\n",
    "\n",
    "As found above we have a complete recommendation dataset for TSB. So we only need to scrape the ATSB reports for recommendations.recommendation_scraper\n",
    "\n",
    "This can be done by reading the safety actions section I believe.\n",
    "\n",
    "Itm ight even be possible to do it with just regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_titles = pd.read_pickle('../../output/report_titles.pkl')\n",
    "parsed_reports = pd.read_pickle('../../output/parsed_reports.pkl')\n",
    "all_reports = report_titles.merge(parsed_reports, how='right', on='report_id')\n",
    "atsb_reports = all_reports[all_reports['report_id'].str.startswith('ATSB') & (all_reports['investigation_type'] != 'short')]\n",
    "atsb_reports.set_index('report_id', inplace=True)\n",
    "atsb_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_atsb = atsb_reports.sample(frac=0.1, random_state=42)\n",
    "\n",
    "\n",
    "sample_dir = 'sample_atsb'\n",
    "\n",
    "if os.path.exists(sample_dir):\n",
    "    shutil.rmtree(sample_dir)\n",
    "\n",
    "os.mkdir(sample_dir)\n",
    "for report_id in sample_atsb['report_id']:\n",
    "    if not os.path.exists(f'../../output/report_pdfs/{report_id}.pdf'):\n",
    "        continue\n",
    "    shutil.copy(f'../../output/report_pdfs/{report_id}.pdf', f'{sample_dir}/{report_id}.pdf')\n",
    "\n",
    "sample_atsb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking through the entire sample it seems that only abotu 2 reports ahve recommendations. I dont know if this is just because the didnt have recommendation or they are listed elsewhere.else\n",
    "\n",
    "I am going to have a look into TAIC and ATSBs recommendations datasets to see how many there are per report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tsb_recommendations\n",
    "report_groups = [v.reset_index(drop=True) for k, v in df.groupby(\"report_id\")]\n",
    "\n",
    "widened_df = pd.DataFrame(\n",
    "    {\n",
    "        \"report_id\": df.groupby(\"report_id\").groups.keys(),\n",
    "        \"recommendations\": report_groups,\n",
    "    }\n",
    ")\n",
    "\n",
    "all_recommendations = pd.concat([widened_df, taic_recommendations], axis=0)\n",
    "\n",
    "all_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_titles = pd.read_pickle('../../output/report_titles.pkl')\n",
    "report_titles['agency'] = report_titles['report_id'].str[:4]\n",
    "report_titles.value_counts('agency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can see that the TSB only has about 100 reports which have recommendations. However TAIC has about 300 reports in that same time period. This means that TAIC is releasing alot more recomendations. This is equally curious as TAIC has only released about 545 reports whereas TSB has done 1500 in that same time period. Meaning that 1/15 TSB reprots has recommendations but taic is about 1/2. About 8 times more. I know that alot of tSB reports are short rpeorts so that will account for some but not all of this difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_atsb['content_section'] = sample_atsb.apply(\n",
    "    lambda x: ReportExtracting.ReportExtractor(x['text'], x['report_id'], x['headers']).extract_contents_section(), axis=1    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ReportExtracting)\n",
    "sample_atsb['recommendation_sections'] = sample_atsb.progress_apply(\n",
    "    lambda x: ReportExtracting.RecommendationsExtractor(x['text'], x['report_id'], x['headers'])._extract_recommendation_section_text(), axis=1\n",
    ")\n",
    "sample_atsb.to_pickle(\"sample_atsb_df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost ot read all of safety actions sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "encoder = tiktoken.encoding_for_model('gpt-4o')\n",
    "\n",
    "sample_atsb['recommendation_section_tokens'] = sample_atsb['recommendation_sections'].progress_apply(\n",
    "    lambda x: len(encoder.encode(x)) if x else 0\n",
    ")\n",
    "\n",
    "sample_atsb.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(atsb_reports) * sample_atsb['recommendation_section_tokens'].mean() / 1_000) * 0.00250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the safety action section\n",
    "Now that the safety action sections have been extracted I can read them with the use of an LLM. It will be a simple query just to extract the recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ReportExtracting)\n",
    "sample_atsb['recommendations'] = sample_atsb.progress_apply(\n",
    "    lambda x:  ReportExtracting.RecommendationsExtractor(x['text'], x['report_id'], x['headers'])._extract_recommendations_from_text(x['recommendation_sections']) if x['recommendation_sections'] else None, axis=1\n",
    ")\n",
    "sample_atsb.to_pickle(\"sample_atsb_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_atsb = pd.read_pickle(\"sample_atsb_df\")\n",
    "sample_atsb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_pickle(\"recommendation_test_data.pkl\")\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = sample_atsb.set_index('report_id').loc[\n",
    "    [\"ATSB_a_2002_780\", \"ATSB_m_2005_215\", \"ATSB_a_2021_005\", \"ATSB_m_2008_012\", \"ATSB_r_2015_007\", # For reading recommendation_sections\n",
    "     \"ATSB_m_2001_163\", \"ATSB_a_2002_710\", \"ATSB_r_2014_024\", \"ATSB_m_2006_234\", \"ATSB_r_2004_004\", \"ATSB_a_2003_980\", \"ATSB_a_2017_105\"] # For extracting pages to read\n",
    "    ][[\"text\", \"headers\", \"content_section\", \"recommendation_sections\", \"recommendations\"]]\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.loc['ATSB_m_2008_012', 'recommendations'] = None\n",
    "test_data.loc['ATSB_a_2002_780', 'recommendations'] = None\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.rename(columns={\"recommendation_sections\": \"recommendation_section\"}).to_pickle(\"recommendation_test_data.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete run through for ATSB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ReportExtracting)\n",
    "atsb_reports['recommendations'] = atsb_reports.progress_apply(\n",
    "    lambda x:  ReportExtracting.RecommendationsExtractor(x['text'], x.name, x['headers']).extract_recommendations(), axis=1\n",
    ")\n",
    "atsb_reports.to_pickle(\"atsb_recommendations\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taic-report-engine-vkGeZcZ8-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
